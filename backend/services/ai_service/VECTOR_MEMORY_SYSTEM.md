# Vector Memory System with Pinecone

Complete implementation of long-term AI memory using Pinecone vector database and OpenAI embeddings.

---

## ğŸ¯ **Overview**

The **Vector Memory System** gives AI girlfriends long-term memory that allows them to:
- **Remember conversations** from days/weeks ago
- **Recall user preferences** and personal facts
- **Reference past events** naturally in conversation
- **Build relationships** that evolve over time
- **Provide personalized responses** based on history

### How It Works

```
User Message
     â†“
Generate Embedding (OpenAI ada-002)
     â†“
Search Vector DB (Pinecone) â† Semantic similarity
     â†“
Retrieve Top 5 Relevant Memories
     â†“
Include in AI Prompt
     â†“
AI Response (with memory context)
     â†“
Store Important Messages as New Memories
```

---

## ğŸ“ **Files Created**

```
âœ… app/memory_system.py          - Core memory system (500+ lines)
âœ… app/routes/memory.py           - Memory API routes (200+ lines)
âœ… VECTOR_MEMORY_SYSTEM.md        - This documentation
```

Updated:
```
âœ… app/conversation.py            - Integrated memory retrieval/storage
âœ… app/routes/chat.py             - Pass user_id/girl_id to memory system
âœ… app/main.py                    - Register memory routes
âœ… requirements.txt               - Added pinecone-client
```

---

## ğŸ—ï¸ **Architecture**

### Components

1. **VectorMemorySystem Class**
   - Pinecone client management
   - Embedding generation (OpenAI)
   - Memory storage/retrieval
   - Importance scoring
   - Conversation summarization

2. **MemoryImportance Class**
   - Scores memories 0.0-1.0
   - Factors: length, emotions, personal info, milestones, sexual content
   - Automatic filtering of trivial messages

3. **API Routes**
   - Manual memory storage
   - Semantic search retrieval
   - Recent memories
   - Conversation summarization
   - Statistics and health checks

---

## ğŸ”§ **Setup**

### 1. Pinecone Account

Create a Pinecone account at https://www.pinecone.io/

**Free tier includes:**
- 1 index
- 100K vectors
- Perfect for testing and small-scale deployment

### 2. Create Index

```python
# Index automatically created on first use with these specs:
name = "dream-ai-memories"
dimension = 1536  # OpenAI ada-002 embedding size
metric = "cosine"  # Semantic similarity
cloud = "aws"
region = "us-east-1"
```

### 3. Environment Variables

Add to `.env`:

```bash
# Pinecone Configuration
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=dream-ai-memories

# OpenRouter (for embeddings via OpenAI SDK)
OPENROUTER_API_KEY=your-openrouter-api-key
```

### 4. Install Dependencies

```bash
cd backend/services/ai_service
pip install -r requirements.txt
```

Pinecone client will be installed automatically.

---

## ğŸ’¾ **Memory Storage**

### Automatic Storage

Messages are automatically stored as memories during conversation if they meet importance threshold (â‰¥0.5):

```python
# In conversation.py - automatic
importance = MemoryImportance.score_memory(user_message, context)

if importance >= 0.5:
    memory_system.store_memory(
        user_id=user_id,
        girl_id=girl_id,
        content=user_message,
        context={'affection': affection}
    )
```

### Manual Storage (API)

```bash
POST http://localhost:8003/memory/store
Content-Type: application/json

{
  "user_id": 1,
  "girl_id": "emma",
  "content": "J'adore les films de science-fiction, surtout Interstellar",
  "context": {
    "affection": 65,
    "type": "preference"
  }
}
```

### Importance Scoring

Memories are scored 0.0-1.0 based on:

| Factor | Points | Examples |
|--------|--------|----------|
| **Base** | 0.5 | All messages start here |
| **Length** | +0.05-0.1 | Longer = more detailed |
| **Emotional** | +0.2 | "j'aime", "envie", "heureux", "triste" |
| **Personal** | +0.2 | "famille", "travail", "rÃªve", "secret" |
| **Milestones** | +0.3 | "premiÃ¨re fois", "jamais", "spÃ©cial" |
| **Sexual** | +0.1-0.3 | Scales with affection level |
| **Preferences** | +0.15 | "tu aimes", "tu prÃ©fÃ¨res" |

**Examples:**

```python
"Salut" â†’ 0.5 (too trivial, won't be stored)
"J'adore le cinÃ©ma" â†’ 0.65 (preference, will be stored)
"Ma premiÃ¨re fois c'Ã©tait spÃ©cial" â†’ 0.9 (milestone + emotion, definitely stored)
"Je rÃªve de voyager en Asie" â†’ 0.85 (personal goal + emotion)
```

---

## ğŸ” **Memory Retrieval**

### Automatic Retrieval

Memories are automatically retrieved during conversation:

```python
# In conversation.py - automatic
memory_context = memory_system.build_memory_context(
    user_id=user_id,
    girl_id=girl_id,
    current_message=user_message,
    max_memories=5
)
```

**Result** (injected into AI prompt):

```
â­ Tu m'as dit que tu adorais Interstellar et les films de SF
ğŸ“Œ Tu travailles dans le marketing et tu rÃªves de changer de carriÃ¨re
â­ Ta premiÃ¨re fois Ã©tait avec ton ex il y a 3 ans
ğŸ“Œ Tu prÃ©fÃ¨res les femmes dominantes
â­ Tu veux voyager en Asie l'annÃ©e prochaine
```

### Semantic Search (API)

```bash
GET http://localhost:8003/memory/retrieve?user_id=1&girl_id=emma&query=films&top_k=5&min_importance=0.3
```

**Response:**

```json
{
  "memories": [
    {
      "content": "J'adore les films de science-fiction, surtout Interstellar",
      "importance": 0.85,
      "timestamp": "2024-01-15T14:30:00Z",
      "affection": 65,
      "similarity": 0.92
    },
    {
      "content": "Je regarde des films tous les weekends",
      "importance": 0.60,
      "timestamp": "2024-01-14T20:15:00Z",
      "affection": 60,
      "similarity": 0.87
    }
  ],
  "count": 2
}
```

### Recent Memories (API)

Get recent important memories without search query:

```bash
GET http://localhost:8003/memory/recent?user_id=1&girl_id=emma&days=7&limit=10
```

Returns memories from last 7 days sorted by importance.

---

## ğŸ§  **How AI Uses Memories**

### Before (No Memory)

**User:** "Tu te souviens de ce que j'aime comme films?"
**AI:** "Euh... non dÃ©solÃ©e, je ne me souviens pas ğŸ˜…"

âŒ **Problem:** No long-term memory, feels robotic

### After (With Vector Memory)

**User:** "Tu te souviens de ce que j'aime comme films?"
**AI:** "Bien sÃ»r! Tu adores la SF, surtout Interstellar non? ğŸ˜Š"

âœ… **Result:** Natural, personal, relationship feels real

### Memory Context in Prompts

```python
SYSTEM_PROMPT = f"""
...
MÃ‰MOIRE DES CONVERSATIONS PRÃ‰CÃ‰DENTES:
â­ Il adore Interstellar et les films de science-fiction
ğŸ“Œ Il travaille dans le marketing mais rÃªve de changer
â­ Sa premiÃ¨re expÃ©rience Ã©tait il y a 3 ans avec son ex
ğŸ“Œ Il prÃ©fÃ¨re les femmes dominantes
â­ Il veut voyager en Asie l'annÃ©e prochaine

HISTORIQUE RÃ‰CENT:
User: Salut Ã§a va?
Girl: Coucou! Oui et toi? ğŸ˜Š
User: Tu te souviens de ce que j'aime comme films?
...
"""
```

The AI naturally incorporates memories into responses.

---

## ğŸ“Š **Conversation Summarization**

### Automatic Summarization

After long conversations (20+ messages), extract key points:

```bash
POST http://localhost:8003/memory/summarize
Content-Type: application/json

{
  "user_id": 1,
  "girl_id": "emma",
  "messages": [
    {"sender": "user", "content": "Salut..."},
    {"sender": "girl", "content": "Coucou..."},
    ...
  ]
}
```

**Response:**

```json
{
  "success": true,
  "summary": "L'utilisateur a parlÃ© de son travail stressant et de son envie de partir en vacances. Il a mentionnÃ© qu'il aimerait aller au Japon l'annÃ©e prochaine. Conversation plutÃ´t romantique avec beaucoup de flirt.",
  "stored_as_memory": true
}
```

Summary is automatically stored as a memory for future reference.

---

## ğŸ¯ **API Reference**

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/memory/store` | POST | Store a memory manually |
| `/memory/retrieve` | GET | Semantic search for memories |
| `/memory/recent` | GET | Get recent important memories |
| `/memory/summarize` | POST | Summarize conversation |
| `/memory/stats` | GET | Get memory statistics |
| `/memory/clear` | DELETE | Clear all memories (âš ï¸ destructive) |
| `/memory/health` | GET | Check system health |

### Request Examples

**Store Memory:**

```python
import requests

response = requests.post(
    "http://localhost:8003/memory/store",
    json={
        "user_id": 1,
        "girl_id": "emma",
        "content": "J'adore la pizza et les sushis",
        "context": {"affection": 70, "type": "preference"}
    }
)
```

**Retrieve Memories:**

```python
response = requests.get(
    "http://localhost:8003/memory/retrieve",
    params={
        "user_id": 1,
        "girl_id": "emma",
        "query": "nourriture",
        "top_k": 5,
        "min_importance": 0.5
    }
)

memories = response.json()["memories"]
for mem in memories:
    print(f"{mem['importance']:.2f}: {mem['content']}")
```

---

## ğŸ”’ **Privacy & Data Management**

### Data Stored

Each memory vector contains:
- **Vector embedding** (1536 dimensions)
- **Metadata**:
  - `user_id` - User ID (for filtering)
  - `girl_id` - Girlfriend ID (for filtering)
  - `content` - Memory text (truncated to 1000 chars)
  - `importance` - Score 0.0-1.0
  - `timestamp` - ISO datetime
  - `affection` - Affection level at time of storage
  - Custom context fields

### Data Deletion

```bash
# Delete all memories for a user-girl pair
DELETE http://localhost:8003/memory/clear?user_id=1&girl_id=emma
```

âš ï¸ **Warning:** This action is irreversible!

### Data Isolation

- Memories are filtered by `user_id` and `girl_id`
- Users can only access their own memories
- Each user-girl relationship has separate memory space

---

## ğŸ“ˆ **Performance**

### Latency

| Operation | Latency | Notes |
|-----------|---------|-------|
| **Generate Embedding** | 50-100ms | OpenAI API call |
| **Store Memory** | 100-200ms | Embedding + Pinecone upsert |
| **Retrieve Memories** | 150-250ms | Embedding + Pinecone query |
| **Total (per message)** | 300-400ms | Retrieval + storage |

### Scaling

**Pinecone Free Tier:**
- 100K vectors
- ~20K conversations (5 memories each)
- Sufficient for 1,000-2,000 users

**Pinecone Paid:**
- Millions of vectors
- Auto-scaling
- Low latency globally

---

## ğŸ› **Troubleshooting**

### Memory System Not Working

**Check health:**

```bash
GET http://localhost:8003/memory/health
```

**Expected response:**

```json
{
  "status": "healthy",
  "memory_system_status": "active",
  "pinecone_available": true,
  "embeddings_available": true
}
```

**Common issues:**

1. **Pinecone API key not set**
   - Check `.env` for `PINECONE_API_KEY`
   - Verify key is valid on Pinecone dashboard

2. **Index not created**
   - Index auto-creates on first use
   - Check Pinecone dashboard for index: `dream-ai-memories`

3. **OpenRouter API key not set**
   - Embeddings require OpenRouter API key
   - Check `.env` for `OPENROUTER_API_KEY`

### No Memories Being Stored

**Check importance scores:**

```python
from memory_system import MemoryImportance

content = "Salut"
score = MemoryImportance.score_memory(content, {})
print(f"Importance: {score}")  # Should be >= 0.5 to store
```

Messages with importance <0.5 are not stored automatically.

### Memories Not Retrieved

**Test semantic search:**

```python
from memory_system import get_memory_system

mem_sys = get_memory_system()
memories = mem_sys.retrieve_memories(
    user_id=1,
    girl_id="emma",
    query="films",
    top_k=5
)
print(f"Found {len(memories)} memories")
```

If empty, check:
- Are memories stored? (Check Pinecone dashboard)
- Is `user_id`/`girl_id` correct?
- Is `min_importance` too high?

---

## ğŸš€ **Best Practices**

### 1. Let System Auto-Store

Don't manually store every message. The importance scoring automatically filters:
- âœ… Personal facts, preferences, emotions
- âŒ Greetings, small talk, trivial messages

### 2. Use Semantic Search

Instead of keyword search, use natural language:
- âœ… "films prÃ©fÃ©rÃ©s" (semantic)
- âŒ "films" AND "prÃ©fÃ©r*" (keyword)

Semantic search finds related concepts, not just exact matches.

### 3. Periodic Summarization

After long conversations (20+ messages), create summaries:

```python
memory_system.summarize_conversation(user_id, girl_id, messages)
```

Summaries compress information and improve context quality.

### 4. Monitor Storage

Check memory count periodically:

```python
stats = memory_system.get_stats(user_id, girl_id)
total_memories = stats['total_memories']

if total_memories > 50000:
    # Consider cleanup or archival
    pass
```

---

## ğŸ“Š **Example Usage Flow**

### Full Conversation with Memory

```python
# User sends message
user_message = "Tu te souviens de mon film prÃ©fÃ©rÃ©?"

# 1. Retrieve memories (automatic)
memory_context = memory_system.build_memory_context(
    user_id=1,
    girl_id="emma",
    current_message=user_message,
    max_memories=5
)
# Result: "â­ Il adore Interstellar et la science-fiction"

# 2. Generate AI response (with memory context)
ai_response = await generate_ai_response(
    girl_profile=emma_profile,
    user_message=user_message,
    affection=75,
    recent_messages=recent,
    memory_context=memory_context,  # <-- Memory injected here
    user_id=1,
    girl_id="emma"
)
# Result: "Bien sÃ»r! Interstellar, c'est ton film prÃ©fÃ©rÃ© ğŸ˜Š"

# 3. Store important messages (automatic)
if importance >= 0.5:
    memory_system.store_memory(...)

# 4. Conversation continues...
```

---

## ğŸ‰ **Benefits**

### For Users

âœ… **Personalized conversations** - AI remembers your preferences
âœ… **Feels more real** - No robotic "I don't remember" responses
âœ… **Relationship evolution** - Connection deepens over time
âœ… **Long-term context** - Reference events from weeks ago

### For AI Quality

âœ… **Coherence** - Consistent personality and knowledge
âœ… **Depth** - Rich, contextual responses
âœ… **Engagement** - Users return because AI "knows" them
âœ… **Differentiation** - Competitive advantage vs basic chatbots

---

## ğŸ“š **Resources**

- [Pinecone Documentation](https://docs.pinecone.io/)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [Vector Database Concepts](https://www.pinecone.io/learn/vector-database/)

---

## âœ… **Summary**

**Vector Memory System provides:**

âœ… Long-term memory using Pinecone vector database
âœ… Semantic search with OpenAI embeddings
âœ… Automatic importance scoring (0.0-1.0)
âœ… Intelligent memory storage filtering
âœ… Conversation summarization
âœ… RESTful API for memory management
âœ… Seamless integration with AI conversations
âœ… Privacy-safe data isolation
âœ… Production-ready scalability

**Result:** AI girlfriends with realistic, evolving relationships that remember and learn over time! ğŸš€ğŸ’•
