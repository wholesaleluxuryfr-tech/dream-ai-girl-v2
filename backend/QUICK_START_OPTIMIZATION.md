# Quick Start: Database Optimization

Fast guide to implementing the database optimizations in your service.

## ðŸš€ In 5 Minutes

### 1. Run Migrations (Add Indexes)

```bash
cd backend
python scripts/run_migrations.py
```

Expected: `âœ… All migrations completed successfully!`

### 2. Restart All Services

```bash
docker-compose restart
```

Services will now use optimized connection pooling.

### 3. Monitor Performance

```bash
python scripts/monitor_performance.py
```

Target metrics:
- Cache hit rate: **>70%**
- API response time: **<200ms**
- Pool utilization: **<80%**

---

## ðŸ’¡ Using Optimizations in Your Code

### Import Optimized Functions

```python
# In your service routes
from shared.config.database_config import (
    get_db,  # Drop-in replacement
    get_conversation_optimized,
    bulk_insert_optimized,
    profile_query
)

from shared.utils.cache_strategy import (
    cache_result,
    cache_conversation_history,
    get_cached_conversation,
    cache_invalidate,
    CacheKeys,
    CacheTTL
)
```

### Add Caching to Endpoints

**Before:**
```python
@router.get("/users/{user_id}")
def get_user(user_id: int, db: Session = Depends(get_db)):
    return db.query(User).filter(User.id == user_id).first()
```

**After (with caching):**
```python
from shared.utils.cache_strategy import cache_result, CacheTTL

@cache_result("user:profile:{user_id}", ttl=CacheTTL.USER_PROFILE)
def get_user_from_db(user_id: int, db: Session):
    return db.query(User).filter(User.id == user_id).first()

@router.get("/users/{user_id}")
def get_user(user_id: int, db: Session = Depends(get_db)):
    user = get_user_from_db(user_id, db)
    return user  # Cached for 15 minutes!
```

### Cache Conversation History

```python
@router.get("/chat/{girl_id}/messages")
async def get_messages(
    girl_id: str,
    user_id: int,
    limit: int = 100,
    db: Session = Depends(get_db)
):
    # Try cache first
    cached = get_cached_conversation(user_id, girl_id, limit)
    if cached:
        return {"messages": cached, "cached": True}

    # Cache miss - query database with optimized function
    messages = get_conversation_optimized(db, user_id, girl_id, limit)

    # Cache for next request
    cache_conversation_history(user_id, girl_id, messages, limit)

    return {"messages": messages, "cached": False}
```

### Invalidate Cache on Updates

```python
@router.post("/chat/{girl_id}/send")
async def send_message(
    girl_id: str,
    message: SendMessageRequest,
    db: Session = Depends(get_db)
):
    # Save message
    new_message = ChatMessage(
        user_id=message.user_id,
        girl_id=girl_id,
        content=message.content
    )
    db.add(new_message)
    db.commit()

    # Invalidate conversation cache
    cache_invalidate(
        CacheKeys.CONVERSATION_LATEST,
        user_id=message.user_id,
        girl_id=girl_id,
        limit=100
    )

    return {"success": True}
```

### Use Bulk Operations

**Before (slow):**
```python
for msg in messages:
    db.add(ChatMessage(**msg))
db.commit()  # Many INSERT queries
```

**After (fast):**
```python
from shared.config.database_config import bulk_insert_optimized

bulk_insert_optimized(db, ChatMessage, messages, batch_size=1000)
# Single batch INSERT (10x faster)
```

---

## ðŸŽ¯ Common Patterns

### Pattern 1: High-Frequency Read Endpoint

Use caching decorator:

```python
@cache_result("matches:user:{user_id}", ttl=CacheTTL.USER_PROFILE)
def get_user_matches_cached(user_id: int, db: Session):
    return db.query(Match).filter(Match.user_id == user_id).all()
```

### Pattern 2: Counter/Incrementer

Use Redis atomic operations:

```python
from shared.utils.cache_strategy import increment_affection_cached

# Increment in Redis (fast)
new_affection = increment_affection_cached(user_id, girl_id, amount=5)

# Sync to DB every 10 points or on logout
if new_affection % 10 == 0:
    match = db.query(Match).filter(...).first()
    match.affection = new_affection
    db.commit()
```

### Pattern 3: Leaderboard

Use Redis sorted sets:

```python
from shared.utils.cache_strategy import update_leaderboard_xp, get_leaderboard_top

# Update user XP
user.xp += 50
db.commit()
update_leaderboard_xp(user.id, user.xp)

# Get top 100 users (instant)
top_users = get_leaderboard_top(limit=100)
```

### Pattern 4: Session Management

Cache user sessions:

```python
from shared.utils.cache_strategy import cache_user_session, get_cached_session

# On login
session_data = {
    "user_id": user.id,
    "username": user.username,
    "access_token": access_token,
    "refresh_token": refresh_token
}
cache_user_session(user.id, session_data)

# On subsequent requests (validate token)
session = get_cached_session(user_id)
if not session:
    raise HTTPException(401, "Session expired")
```

---

## ðŸ” Debugging

### Check if Cache is Working

```python
from shared.utils.cache_strategy import get_cache_stats

stats = get_cache_stats()
print(f"Cache hit rate: {stats['hit_rate'] * 100:.1f}%")
print(f"Total keys: {stats['total_keys']}")
```

### Check if Index is Used

```python
from sqlalchemy import text

result = db.execute(text("""
    EXPLAIN ANALYZE
    SELECT * FROM chat_messages
    WHERE user_id = 1 AND girl_id = 'sophia'
    ORDER BY timestamp DESC LIMIT 100
"""))
print(result.fetchall())
# Should show: "Index Scan using idx_messages_conversation"
```

### Monitor Connection Pool

```python
from shared.config.database_config import get_db_stats

stats = get_db_stats()
print(f"Active: {stats['checked_out']}/{stats['pool_size']}")
print(f"Idle: {stats['checked_in']}")
```

---

## ðŸ“Š Expected Improvements

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Get conversation (100 msgs) | 450ms | 45ms | **10x faster** |
| Get user matches | 320ms | 38ms | **8x faster** |
| Send message | 280ms | 92ms | **3x faster** |
| Cache hit rate | 0% | 80%+ | **80% fewer DB queries** |

---

## âš ï¸ Common Mistakes

### âŒ Forgetting to Invalidate Cache

```python
# BAD: Cache becomes stale
user.tokens += 100
db.commit()
# Cached user still has old token count!
```

```python
# GOOD: Invalidate after update
user.tokens += 100
db.commit()
cache_invalidate(CacheKeys.USER_PROFILE, user_id=user.id)
```

### âŒ Caching Too Long

```python
# BAD: Affection changes frequently, cache too long
@cache_result("affection:{user_id}:{girl_id}", ttl=3600)  # 1 hour
```

```python
# GOOD: Use appropriate TTL
@cache_result("affection:{user_id}:{girl_id}", ttl=CacheTTL.MATCH_AFFECTION)  # 5 min
```

### âŒ N+1 Query Problem

```python
# BAD: Queries DB for each match
for match in matches:
    photos = db.query(Photo).filter(Photo.girl_id == match.girl_id).all()
```

```python
# GOOD: Single query with JOIN
from sqlalchemy.orm import joinedload

matches = db.query(Match).options(
    joinedload(Match.photos)
).filter(Match.user_id == user_id).all()
```

---

## ðŸ“š Learn More

- Full guide: [DATABASE_OPTIMIZATION.md](./DATABASE_OPTIMIZATION.md)
- Monitor: `python scripts/monitor_performance.py`
- Migrations: `backend/shared/migrations/001_add_indexes.sql`

---

**Questions?** Check the full documentation or run the monitoring dashboard.
